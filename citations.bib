
@article{barbosaSyllabletimingBrazilianPortuguese2000,
  title = {"{{Syllable}}-Timing in {{Brazilian Portuguese}}": Uma Cr{\'i}tica a {{Roy Major}}},
  shorttitle = {"{{Syllable}}-Timing in {{Brazilian Portuguese}}"},
  author = {Barbosa, Pl{\'i}nio Almeida},
  year = {2000},
  volume = {16},
  pages = {369--402},
  issn = {0102-4450},
  doi = {10.1590/S0102-44502000000200006},
  abstract = {A tese de R. Major, segundo a qual haveria evid{\^e}ncias para se considerar o portugu{\^e}s brasileiro (PB) como "stress-timing" ou tendendo para tal, {\'e} rediscutida. As quest{\~o}es fon{\'e}tico-fonol{\'o}gicas suscitadas pela dicotomia de l{\'i}nguas "stress-timed" e "syllable-timed" e o suposto isocronismo absoluto s{\~a}o apresentadas sob um prisma estritamente pros{\'o}dico-temporal. Um modelo empregando dois osciladores acoplados (acentual e sil{\'a}bico) possibilita a caracteriza{\c c}{\~a}o biparam{\'e}trica (taxa de elocu{\c c}{\~a}o e for{\c c}a de acoplamento) de um conjunto arbitr{\'a}rio de frases de uma l{\'i}ngua e permite mostrar que, em PB, h{\'a} alto grau de "syllable-timing". {\`A} luz de uma an{\'a}lise fon{\'e}tica mais cuidadosa dos fatores ligados ao ritmo, mostra-se que os argumentos apresentados por Major para justificar "stress-timing" em PB s{\~a}o completamente equivocados.
          , 
            This paper reintroduces the discussion about stress-timing in Brazilian Portuguese (BP). It begins by surveying some phonetic and phonological issues raised by the syllable- vs stress-timed dichotomy which culminated with the emergence of the p-center notion. Strict considerations of timing of V-V units and stress groups are taken into account to analyze the long term coupling of two basic oscillators (vowel and stress flow). This coupling allows a two-parameter characterization of language rhythms (coupling strength and speech rate) revealing that BP utterances present a high-degree of syllable-timing. A comparison with other languages, including European Portuguese, is also presented. The results analyzed indicate that Major's arguments for considering Portuguese (sic) as stress-timing are misleading.},
  file = {C\:\\Users\\renan\\Zotero\\storage\\95Y6SX5G\\Barbosa - 2000 - Syllable-timing in Brazilian Portuguese uma cr√≠.pdf},
  journal = {DELTA: Documenta{\c c}{\~a}o de Estudos em Ling{\"u}{\'i}stica Te{\'o}rica e Aplicada},
  number = {2}
}

@article{dimitriadisEnhancementsAudioonlyDiarization2019,
  title = {Enhancements for {{Audio}}-Only {{Diarization Systems}}},
  author = {Dimitriadis, Dimitrios},
  year = {2019},
  month = aug,
  abstract = {In this paper two different approaches to enhance the performance of the most challenging component of a Speaker Diarization system are presented, i.e. the speaker clustering part. A processing step is proposed enhancing the input features with a temporal smoothing process combined with nonlinear filtering. We, also, propose improvements on the Deep Embedded Clustering (DEC) algorithm -- a nonlinear feature transformation. The performance of these enhancements is compared with different clustering algorithms, such as the UISRNN, k-Means, Spectral clustering and x-Means. The evaluation is held on three different tasks, i.e. the AMI, DIHARD and an internal meeting transcription task. The proposed approaches assume a known number of speakers and time segmentations for the audio files. Since, we focus only on the clustering component of diarization for this work, the segmentation provided is assumed perfect. Finally, we present how supervision, in the form of given speaker profiles, can further improve the overall diarization performance. The proposed enhancements yield substantial relative improvements in all 3 tasks, with 20\textbackslash\% in AMI and 19\textbackslash\% better than the best diarization system for DIHARD task, when the number of speakers is known.},
  archivePrefix = {arXiv},
  eprint = {1909.00082},
  eprinttype = {arxiv},
  file = {C\:\\Users\\renan\\Zotero\\storage\\8P4SLIKC\\Dimitriadis - 2019 - Enhancements for Audio-only Diarization Systems.pdf;C\:\\Users\\renan\\Zotero\\storage\\WUVWNVCG\\1909.html},
  journal = {arXiv:1909.00082 [cs, eess]},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  primaryClass = {cs, eess}
}

@article{dlib09,
  title = {Dlib-Ml: {{A}} Machine Learning Toolkit},
  author = {King, Davis E.},
  year = {2009},
  volume = {10},
  pages = {1755--1758},
  journal = {Journal of Machine Learning Research}
}

@article{Hunter:2007,
  title = {Matplotlib: {{A 2D}} Graphics Environment},
  author = {Hunter, J. D.},
  year = {2007},
  volume = {9},
  pages = {90--95},
  publisher = {{IEEE COMPUTER SOC}},
  doi = {10.1109/MCSE.2007.55},
  abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},
  journal = {Computing in Science \& Engineering},
  number = {3}
}

@inproceedings{Kluyver:2016aa,
  title = {Jupyter {{Notebooks}} \textendash{} a Publishing Format for Reproducible Computational Workflows},
  booktitle = {Positioning and Power in Academic Publishing: {{Players}}, Agents and Agendas},
  author = {Kluyver, Thomas and {Ragan-Kelley}, Benjamin and P{\'e}rez, Fernando and Granger, Brian and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvain and Ivanov, Paul and Avila, Dami{\'a}n and Abdalla, Safia and Willing, Carol},
  editor = {Loizides, F. and Schmidt, B.},
  year = {2016},
  pages = {87--90},
  organization = {{IOS Press}}
}

@inproceedings{lelanSpeakerDiarizationUnsupervised2016,
  title = {Speaker {{Diarization With Unsupervised Training Framework}}},
  booktitle = {41st {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}} 2016)},
  author = {Le Lan, Ga{\"e}l and Meignier, Sylvain and Charlet, Delphine and Del{\'e}glise, Paul},
  year = {2016},
  month = mar,
  pages = {5},
  address = {{Shanghai, China}},
  doi = {10.1109/ICASSP.2016.7472741},
  abstract = {This paper investigates single and cross-show diarization based on an unsupervised i-vector framework, on French TV and Radio corpora. This framework uses speaker clustering as a way to automatically select data from unlabeled corpora to train i-vector PLDA models. Performances between supervised and unsupervised models are compared. The experimental results on two distinct test corpora (one TV, one Radio) show that unsupervised models perform as good as supervised models for both tasks. Such results indicate that performing an effective cross-show diarization on new language or new domain data in the future should not depend on the availability of manually annotated data.},
  file = {C\:\\Users\\renan\\Zotero\\storage\\WDAI2TCA\\Le Lan et al. - 2016 - Speaker Diarization With Unsupervised Training Fra.pdf}
}

@inproceedings{mccowanAMIMeetingCorpus2005,
  title = {The {{AMI Meeting Corpus}}},
  booktitle = {In: {{Proceedings Measuring Behavior}} 2005, 5th {{International Conference}} on {{Methods}} and {{Techniques}} in {{Behavioral Research}}. {{L}}.{{P}}.{{J}}.{{J}}. {{Noldus}}, {{F}}. {{Grieco}}, {{L}}.{{W}}.{{S}}. {{Loijens}} and {{P}}.{{H}}. {{Zimmerman}} ({{Eds}}.), {{Wageningen}}: {{Noldus Information Technology}}},
  author = {Mccowan, I. and Lathoud, G. and Lincoln, M. and Lisowska, A. and Post, W. and Reidsma, D. and Wellner, P.},
  year = {2005},
  abstract = {To support multi-disciplinary research in the AMI (Augmented Multi-party Interaction) project, a 100 hour corpus of meetings is being collected. This corpus is being recorded in several instrumented rooms equipped with a variety of microphones, video cameras, electronic pens, presentation slide capture and white-board capture devices. As well as real meetings, the corpus contains a significant proportion of scenario-driven meetings, which have been designed to elicit a rich range of realistic behaviors. To facilitate research, the raw data are being annotated at a number of levels including speech transcriptions, dialogue acts and summaries. The corpus is being distributed using a web server designed to allow convenient browsing and download of multimedia content and associated annotations. This article first overviews AMI research themes, then discusses corpus design, as well as data collection, annotation and distribution.},
  file = {C\:\\Users\\renan\\Zotero\\storage\\W3JCAPJK\\Mccowan et al. - 2005 - The AMI Meeting Corpus.pdf;C\:\\Users\\renan\\Zotero\\storage\\FHP28W4E\\summary.html}
}

@inproceedings{mckinney-proc-scipy-2010,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Proceedings of the 9th {{Python}} in {{Science Conference}}},
  author = {{Wes McKinney}},
  editor = {{van der Walt}, St{\'e}fan and {Jarrod Millman}},
  year = {2010},
  pages = {51--56}
}

@article{opencv_library,
  title = {The {{OpenCV}} Library},
  author = {Bradski, G.},
  year = {2000},
  citeulike-article-id = {2236121},
  journal = {Dr. Dobb's Journal of Software Tools},
  keywords = {bibtex-import},
  posted-at = {2008-01-15 19:21:54},
  priority = {4}
}

@article{oxenhamPitchPerception2012,
  title = {Pitch {{Perception}}},
  author = {Oxenham, Andrew J.},
  year = {2012},
  month = sep,
  volume = {32},
  pages = {13335--13338},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3815-12.2012},
  abstract = {Pitch is one of the primary auditory sensations and plays a defining role in music, speech, and auditory scene analysis. Although the main physical correlate of pitch is acoustic periodicity, or repetition rate, there are many interactions that complicate the relationship between the physical stimulus and the perception of pitch. In particular, the effects of other acoustic parameters on pitch judgments, and the complex interactions between perceptual organization and pitch, have uncovered interesting perceptual phenomena that should help to reveal the underlying neural mechanisms.},
  copyright = {Copyright \textcopyright{} 2012 the authors 0270-6474/12/3213335-04\$15.00/0},
  file = {C\:\\Users\\renan\\Zotero\\storage\\4UP3WFTR\\Oxenham - 2012 - Pitch Perception.pdf;C\:\\Users\\renan\\Zotero\\storage\\GIDP5F5Y\\13335.html},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {39},
  pmid = {23015422}
}

@inproceedings{snyderXVectorsRobustDNN2018,
  title = {X-{{Vectors}}: {{Robust DNN Embeddings}} for {{Speaker Recognition}}},
  shorttitle = {X-{{Vectors}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Snyder, David and {Garcia-Romero}, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  year = {2018},
  month = apr,
  pages = {5329--5333},
  publisher = {{IEEE}},
  address = {{Calgary, AB}},
  doi = {10.1109/ICASSP.2018.8461375},
  abstract = {In this paper, we use data augmentation to improve performance of deep neural network (DNN) embeddings for speaker recognition. The DNN, which is trained to discriminate between speakers, maps variable-length utterances to fixed-dimensional embeddings that we call x-vectors. Prior studies have found that embeddings leverage large-scale training datasets better than i-vectors. However, it can be challenging to collect substantial quantities of labeled data for training. We use data augmentation, consisting of added noise and reverberation, as an inexpensive method to multiply the amount of training data and improve robustness. The x-vectors are compared with i-vector baselines on Speakers in the Wild and NIST SRE 2016 Cantonese. We find that while augmentation is beneficial in the PLDA classifier, it is not helpful in the i-vector extractor. However, the x-vector DNN effectively exploits data augmentation, due to its supervised training. As a result, the x-vectors achieve superior performance on the evaluation datasets.},
  file = {C\:\\Users\\renan\\Zotero\\storage\\95UVGLQV\\Snyder et al. - 2018 - X-Vectors Robust DNN Embeddings for Speaker Recog.pdf},
  isbn = {978-1-5386-4658-8},
  language = {en}
}

@article{tensorflow2015-whitepaper,
  title = {{{TensorFlow}}: {{Large}}-Scale {{Machine Learning}} on {{Heterogeneous Systems}}},
  author = {Abadi, Mart{\'i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man{\'e}, Dandelion and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi{\'e}gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  year = {2015},
  abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, generalpurpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous ``parameter server'' designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.}
}

@article{zewoudieUseLongtermFeatures2018,
  title = {The Use of Long-Term Features for {{GMM}}- and i-Vector-Based Speaker Diarization Systems},
  author = {Zewoudie, Abraham Woubie and Luque, Jordi and Hernando, Javier},
  year = {2018},
  month = sep,
  volume = {2018},
  pages = {14},
  issn = {1687-4722},
  doi = {10.1186/s13636-018-0140-x},
  abstract = {Several factors contribute to the performance of speaker diarization systems. For instance, the appropriate selection of speech features is one of the key aspects that affect speaker diarization systems. The other factors include the techniques employed to perform both segmentation and clustering. While the static mel frequency cepstral coefficients are the most widely used features in speech-related tasks including speaker diarization, several studies have shown the benefits of augmenting regular speech features with the static ones.},
  file = {C\:\\Users\\renan\\Zotero\\storage\\GXP27EB6\\Zewoudie et al. - 2018 - The use of long-term features for GMM- and i-vecto.pdf},
  journal = {EURASIP Journal on Audio, Speech, and Music Processing},
  language = {en},
  number = {1}
}


