\chapter{Revisão Bibliográfica}

\section{Trabalhos Correlatos}
\label{sec:related-work}

O problema de diarização de locutor é historicamente abordado de duas maneiras distintas.
A abordagem tradicional envolve a extração de vetores de características do áudio que se deseja diarizar, podendo ser estes \textit{I-Vectors} \cite{dehakFrontEndFactorAnalysis2011}, extraídos por meio de transformações matriciais aplicadas sobre o sinal, ou \textit{X-Vectors} \cite{snyderXVectorsRobustDNN2018}, obtidos através do uso de redes neurais profundas.
A partir de então, estes vetores podem ser clusterizados \cite{sellSpeakerDiarizationPlda2014} quando informações referentes ao número de locutores é conhecido, ou, mais recentemente, utilizados como entrada de uma rede neural LSTM \cite{wangSpeakerDiarizationLSTM2018}.

No entanto, a introdução das redes neurais convolucionais para reconhecimento de ações humanas em sinais de vídeos \cite{ji3DConvolutionalNeural2013, karpathyLargeScaleVideoClassification2014} implicou na concepção de uma nova abordagem.
Nesta, com o objetivo de melhorar a diarização de sinais heterogêneos, é utilizado um algoritmo de reconhecimento de ações também sobre o sinal de vídeo \cite{hersheyAudiovisualGraphicalModels2004}, que se supõe estar sincronizado ao áudio correspondente.
O reconhecimento de ações é, nesse caso, utilizado para identificar a fala do locutor e, quando combinado com os sinais de áudio, é capaz de produzir resultados melhores do que o estado da arte no processamento exclusivo de áudio \cite{ephratLookingListenCocktail2018}.

\section{Fundamentação Teórica}

Nesta seção discutiremos a fundamentação teórica das várias tecnologias utilizadas na execução do trabalho. Primeiramente, na seção \ref{sec:ann}, apresentaremos o conceito de redes neurais artificiais, utilizadas para construção do identificador de fala. Depois, na seção \ref{sec:facialrecog}, discutiremos a técnica de \textit{histograma de gradientes orientados}, utilizada pelo identificador de rostos frontais. Por fim, na seção \ref{sec:faciallm}, falaremos sobre a técnica de alinhamento facial, utilizada para a detecção dos marcadores faciais.

\subsection{Redes Neurais Artificiais}
\label{sec:ann}

Redes Neurais Artificiais são um conjunto de algoritmos inspirados pelo funcionamento do cérebro humano, introduzidos pela primeira vez em 1943 quando Warren McCulloch e Walter Pitts modelaram o funcionamento de neurônios através de circuitos elétricos simples\cite{mccullochLogicalCalculusIdeas1943}. 
Esse modelo continuou evoluindo ao longo dos anos, culminando no desenvolvimento do \textit{Perceptron} por Rosenblatt em 1958 \cite{rosenblattPerceptronProbabilisticModel1958} (figura \ref{fig:perceptron}), um algoritmo de classificação binária semelhante a uma rede neural composta por um único neurônio.

No entanto, devido à falta de capacidade computacional e ao grande volume de dados necessários para o treinamento das redes neurais, estes algoritmos permaneceram apenas um conceito acadêmico durante vários anos.
Somente em 2006, Geoffrey Hinton proporia formalmente o conceito de rede neural profunda \cite{hintonFastLearningAlgorithm2006}, um tipo de rede neural composto por múltiplas camadas de neurônios densamente conectadas.

\begin{figure}[ht]
    \centering
    \input{figures/dnn.tikz}
    \caption{Ilustração de uma rede neural profunda com 3 camadas.}
    \label{fig:dnn}
\end{figure}

Recentemente, com o desenvolvimento de algoritmos para o treinamento de redes neurais em GPU (do Inglês \textit{Graphics Processing Unit}) que possibilitaram o treinamento mais rápido e eficiente de redes neurais de múltiplas camadas, assim como o crescente volume de dados disponível para treinamento, o tópico de redes neurais vem rapidamente ganhando popularidade.
Algoritmos desse tipo já são utilizados em diversas áreas da ciência, incluindo aplicações em medicina \cite{hannunCardiologistLevelArrhythmiaDetection2019,phamPredictingHealthcareTrajectories2017,houDeepSFDeepConvolutional2018}, previsão do tempo \cite{akramSequenceSequenceWeather2016}, veículos autônomos \cite{bojarskiEndEndLearning2016,peddagollaLaneDetectionAutonomous}, entre outras \cite{abiodunStateoftheartArtificialNeural2018}.

Tratam-se de algoritmos próprios para problemas que envolvem o reconhecimento de padrões, e a capacidade de treina-los a partir de dados existentes os torna eficazes para aplicação em tópicos nos quais as relações entre os dados de entrada não sejam totalmente conhecidas.

\subsubsection{Neurônios Artificiais}

Biologicamente, quando o potencial elétrico na base do axônio de um neurônio atinge um limiar pré-determinado através do acúmulo de sinais de entrada recebidos pelos dendritos, um pulso elétrico é gerado e propagado até as sinapses, terminais nos quais o neurônio se conecta com os demais.
Trata-se de um sinal binário; o neurônio pode ou não estar ativado a cada instante. No entanto, a frequência relativa das ativações pode conter informação \cite{behnkeHierarchicalNeuralNetworks2003}.

\begin{figure}[H]
    \centering
    \includesvg[width=0.7\textwidth]{neurono-ido.svg}
    \caption{A estrutura de um neurônio biológico. Imagem adaptada de \cite{dhp1080IdoSkemoPri2016}.}
    \label{fig:bio_neuron}
\end{figure}

Funções de Ativação, também conhecidas como funções de propagação ou neurônios artificiais quando aplicadas no contexto de redes neurais, buscam modelar de forma simplificada esses aspectos biológicos.
Elas recebem como entrada os valores resultantes das camadas anteriores, ponderados por pesos específicos a cada conexão, e, quando estes valores atingem um limiar de excitação pré-determinado, os transformam em uma única saída.

\begin{figure}[H]
    \centering
    \input{figures/perceptron.tikz}
    \caption{O \textit{Perceptron}, uma rede neural com um único neurônio.}
    \label{fig:perceptron}
\end{figure}

Geralmente, a função de ativação é constante e independente do processo de treinamento da rede neural; o ajuste é feito sobre os pesos das conexões, através do algoritmo de retropropagação \cite{dreyfusArtificialNeuralNetworks1990}.
O algoritmo é capaz de, a partir do resultado de uma camada, calcular o efeito de cada peso sobre o gradiente da função.
Assim, ele possibilita a utilização de algoritmos tradicionais de otimização para encontrar os pesos locais de cada conexão em função do efeito global destes, mesmo em redes com múltiplas camadas de centenas de neurônios.

Comumente, são utilizadas como função de ativação as funções ReLU (\textit{Rectified Linear Unit}), tangente hiperbólica, sigmoide, e Heaviside, em função do intervalo de saída e comportamento desejado.

\begin{equation}\label{eq:relu}
    \phi(x) = \left\{
        \begin{array}{ll}
            0, & x \le 0\\
            x, & x > 0
        \end{array}
    \right.
\end{equation}

A função ReLU (equação \ref{eq:relu}), utilizada neste trabalho, tem comportamento tal que sua ativação ocorre sempre que $x>0$, com o valor resultante sendo o próprio valor de $x$. 
Essa função é ideal para aplicações em redes neurais profundas pois o gradiente é preservado após cada camada da rede, o que não ocorre com as funções sigmoide e tangente hiperbólica.
Nessas, o gradiente tende a valores infinitesimalmente pequenos após camadas sucessivas, dificultando o uso do algoritmo de retropropagação.
Além disso, o treinamento de redes neurais profundas que utilizam a função ReLU é mais rápido do que o das outras funções de ativação, devido à sua simplicidade \cite{krizhevskyImageNetClassificationDeep2017}.

\subsubsection{Redes Neurais Convolucionais}
\label{sec:convnet}

Redes Neurais Convolucionais são redes neurais compostas por uma ou mais camadas de convolução.
São ideais para o tratamento de dados matriciais, como por exemplo imagens, que constituem em uma matriz bi-dimensional de pixels, ou vídeos, matrizes tridimensionais compostas por múltiplas imagens dispostas segundo sua relação temporal.
Essas redes são capazes de identificar relações entre os elementos vizinhos de uma matriz e, através da técnica de Max Pooling, focar somente nas regiões mais relevantes da entrada, reduzindo a complexidade do problema quando aplicadas a conjuntos de dados muito grandes.

\paragraph{Convolução e Filtros}
\label{sec:convolution}

A convolução é uma técnica matemática que consiste na aplicação de uma matriz, denominada matriz de convolução ou \textit{filtro} quando utilizada no contexto de processamento de imagens, sobre cada elemento de uma outra matriz.
Esse processo produz uma nova matriz na qual o valor de cada elemento corresponde ao seu valor original combinado com o de seus vizinhos, e ponderados pelos valores da matriz de convolução (denominados \kernel\ da convolução).

Para dados bi-dimensionais, a operação de convolução pode ser descrita da seguinte forma:

\begin{equation}
    g(x,y) = \omega * f(x,y) = \sum\limits_{s=-a}^a\sum\limits_{t=-b}^b\omega(s,t)f(x-s, y-t)
\end{equation}

Essa técnica é frequentemente utilizada em áreas que trabalham com imagens, como na área de veículos autônomos, onde é capaz de identificar as faixas pintadas sobre o asfalto \cite{peddagollaLaneDetectionAutonomous}, assim como outros veículos e pedestres na rua.
Através do uso dessa técnica, é possível remover características da imagem de entrada irrelevantes e enfatizar características mais relevantes para o problema que se deseja resolver, como mostra a figura \ref{fig:conv}.

\begin{figure}[ht]
    \centering
    \input{figures/convolution.tikz}
    \caption{O resultado da aplicação de um \kernel\ simples para detecção de bordas verticais a uma foto. 
    O \kernel\ é aplicado a cada pixel da imagem, substituindo o valor deste pela soma de sua vizinhança ponderada pelos valores da matriz. 
    Foto original obtida de \cite{diliffEnglishLookingEast2015}.}
    \label{fig:conv}
\end{figure}

No contexto de redes neurais convolucionais, isso consiste em neurônios que realizam uma operação de convolução sobre os dados de entrada.
O \kernel\ da matriz de convolução é treinado de forma a identificar os aspectos da entrada mais relevantes para o problema, através do algoritmo de retropropagação.

\paragraph{Pooling}
\label{sec:pooling}

Um outro tipo de camada tradicional nas redes neurais convolucionais é a camada de \textit{pooling}, ou ``agrupamento''.
Esse tipo de camada tem como função reduzir o número e complexidade dos dados de entrada e promover uma melhor generalização espacial dos dados.
Isso é necessários pois as camadas convolucionais tendem a manter a localização espacial das características detectadas na matriz de entrada, informação essa que na maioria dos casos não é relevante para o problema que se deseja resolver.

A operação consiste em subdividir a matriz de entrada em conjuntos de valores e, segundo um critério especificado, escolher entre estes um único valor resultante.

\begin{figure}[ht]
    \centering
    \input{figures/max_pool.tikz}
    \caption{O resultado da operação de \textit{Max Pooling} com dimensão $2\times2$ sobre uma matriz de entrada.}
    \label{fig:maxpool}
\end{figure}

No contexto de redes neurais convolucionais, no entanto, tendo em mente que os valores resultantes da camada convolucional teriam sido filtrados por uma função de ativação não-linear, como a ReLU (equação \ref{eq:relu}), temos que os valores obtidos correspondem à intensidade da ativação dos neurônios.
Assim, devido ao fato de que valores maiores devem corresponder a características de maior importância na matriz de entrada, temos dois critérios mais usados para a operação:

\begin{description}
    \itemsep0em 
    \item \textit{\textbf{Max Pooling}}: Para cada grupo, calcula o valor máximo (figura \ref{fig:maxpool}).
    \item \textit{\textbf{Average Pooling}}: Para cada grupo, calcula a média dos valores.
\end{description}

A escolha entre esses critérios é feita em função do propósito da camada anterior; se esta for, por exemplo, um detector de bordas em imagens, temos que a técnica de \textit{Max Pooling} será preferível, visto que as bordas serão sempre os elementos de maior valor do grupo, enquanto os demais terão valor igual a zero.
Já no caso de se tratar de um reconhecedor de variação temporal, a técnica de \textit{Average Pooling} pode ser preferível, já que será capaz de manter informações sobre o valor médio dos elementos no instante que está sendo comprimido.

\subsection{Histograma de Gradientes Orientados}
\label{sec:facialrecog}

Histograma de Gradientes Orientados, ou HOG, do inglês \textit{Histogram of Oriented Gradients}, é uma técnica de visão computacional utilizada para detecção de objetos em imagens, introduzida pela primeira vez em 1982 por Robert McConnel \cite{mcconnellMethodApparatusPattern1986}, e formalizada em 1994 por Freeman e Roth \cite{freemanOrientationHistogramsHand}.
Trata-se do treinamento de um histograma de blocos descritivos dos gradientes que se espera observar em cada uma das regiões que se deseja reconhecer, e posterior comparação deste com os gradientes de áreas ou células da imagem de entrada.

Neste trabalho utilizaremos a F-HOG\footnote{F-HOG é uma implementação de detector HOG proposta por Felzenszwalb em seu artigo \cite{felzenszwalbObjectDetectionDiscriminatively}. O identificador facial frontal da biblioteca Dlib (seção \ref{subsec:dlib}), utilizado neste trabalho, adota essa implementação.}, uma técnica de HOG que consiste na composição de histograma com 36 descritores por célula utilizado para o treinamento de um classificador SVM (\textit{Support Vector Machine}).
Essa técnica consiste em, primeiramente, calcular os gradientes de cada ponto da imagem, normalizada quanto à cor através de sua conversão a escala de cinza.
Esse cálculo é feito a partir da aplicação de um vetor de diferenciação $[-1, 0, +1]$ e seu transposto a cada pixel da imagem.
O processo calcula um ângulo $\theta$ e intensidade $r$ representativos do gradiente local em cada um dos pontos aos quais é aplicado.

A magnitude de cada gradiente é, então, discretizada conforme a direção entre $p$ direções pré-definidas e adicionada às 4 células adjacentes do histograma, através de sua interpolação bilinear.
A orientação final de cada bloco é então calculada a partir dos gradientes da região espacial que o compõem, por meio da soma de suas componentes.
Isso garante a invariância do reconhecedor a pequenas alterações nas bordas, além de diminuir o tamanho deste, já que em geral o valor resultante das células tenderá a permanecer constante quando agrupadas.

\begin{equation}\label{eq:hog_energy}
    \begin{split}
        N_{\delta,\gamma}(i,j) = & \left(
            \left\Vert C(i,j) \right\Vert ^2 +
            \left\Vert C(i+\delta,j) \right\Vert ^2 +
            \right.\\ 
            & + \left. \left\Vert C(i,j+\gamma) \right\Vert ^2 +
            \left\Vert C(i+\delta,j+\gamma) \right\Vert ^2
            \right)^{1/2}, \qquad \delta,\gamma \in \{-1, 1\}
    \end{split}
\end{equation}

\begin{equation}\label{eq:hog_norm}
    H(i,j) = \left(\begin{matrix}
        T_\alpha(C(i,j)/N_{-1,-1}(i, j))\\
        T_\alpha(C(i,j)/N_{+1,-1}(i, j))\\
        T_\alpha(C(i,j)/N_{+1,+1}(i, j))\\
        T_\alpha(C(i,j)/N_{-1,+1}(i, j))
    \end{matrix}\right)
\end{equation}

É feita, então, a normalização dos blocos descritores.
As componentes de cada célula são normalizadas em relação à energia de sua vizinhança (calculada através da equação \ref{eq:hog_energy}), e truncadas em um valor $\alpha=0.2$, conforme a equação \ref{eq:hog_norm}.
Isso produz uma matriz $H(i,j)$ de dimensão $p\times4$ correspondente a cada célula do histograma, na qual cada elemento representa a normalização da intensidade do gradiente em uma das direções pré-definidas segundo os 4 critérios discutidos.

Os histogramas obtidos a partir dessa técnica são utilizados para treinamento de um classificador SVM.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.27\textwidth]{face_fhog_filters.png}
    \caption{Um exemplo de HOG gerado a partir da imagem de um rosto. Imagem retirada de \cite{kingDlib18Released}.}
    \label{fig:dlib_hog}
\end{figure}

Para a detecção de objetos por meio desta técnica o processo de extração de descritores é repetido, produzindo um histograma para a imagem alvo como um todo.
O classificador visita cada região do histograma em diferentes resoluções por meio de uma \textit{sliding window} piramidal \cite{dalalHistogramsOrientedGradients2005}, detectando as regiões desta que contém as mesmas características dos histogramas com os quais foi treinado.
A implementação em forma de pirâmide da janela de reconhecimento permite que os objetos desejados sejam detectados de maneira independente de suas dimensões na imagem a partir de um único histograma treinado.

\subsection{Alinhamento Facial}
\label{sec:faciallm}

Alinhamento facial é uma técnica que vêm sendo bastante estudada nos últimos anos, com diversos métodos propostos para sua execução \cite{caoFaceAlignmentExplicit2014, liangFaceAlignmentComponentBased2008, dantoneRealtimeFacialFeature2012, xiangxinzhuFaceDetectionPose2012}.
Originalmente introduzida em \cite{yuilleFeatureExtractionFaces1992} por Yuille et al, a técnica busca a identificação de pontos representantes do contorno geométrico de diversas características de rostos em imagens, tais como os olhos, lábios, nariz, e sobrancelhas.

\begin{figure}[ht]
    \centering
    \input{figures/facial_alignment.tikz}
    \caption{Estado do vetor de marcadores faciais em cada iteração do algoritmo de alinhamento facial.}
    \label{fig:faciallm_iters}
\end{figure}

Neste trabalho discutiremos o método proposto por Kazemi e Sullivan \cite{kazemiOneMillisecondFace2014}, que consiste em ajustar iterativamente um conjunto de pontos iniciais obtidos a partir dos dados de treinamento.
Esse ajuste, modelado pela equação \ref{eq:regression}, é feito através da aplicação de uma cascata de florestas de árvores regressoras sobre a imagem de entrada, como mostra a figura \ref{fig:faciallm_iters}.

\begin{equation}\label{eq:regression}
    \hat{S}^{\left( t+1 \right)} = \hat{S}^{\left( t \right)} + r_t(I, \hat{S}^{\left( t \right)})
\end{equation}

Cada regressor consiste em uma árvore de decisão que, a partir da diferença de intensidade entre pares de pixels da imagem, é capaz de escolher um vetor de atualização a ser aplicado sobre o ponto resultante da iteração anterior.
Esses vetores são pré-definidos e constantes, e são atribuídos às folhas da árvore.
Nas primeiras iterações, estes são de maior magnitude, permitindo atualizações maiores nos pontos.
Com cada iteração subsequente, são utilizados vetores de atualização menores, resultando em ajustes finos nos pontos.

As árvores são treinadas utilizando da técnica de \textit{gradient boosting}.
Os pixels a serem considerados como entrada de cada nível da cascata são escolhidos aleatoriamente durante o treinamento, com o único critério sendo a função exponencial de custo definida na equação \ref{eq:prior}.
A aleatoriedade da seleção dessas características de entrada serve para tornar o algoritmo menos sensível a alterações na iluminação.

\begin{equation}\label{eq:prior}
    P(u,v) \propto e^{ -\lambda \left\Vert u-v \right\Vert }
\end{equation}

Essa implementação permite a localização de marcadores faciais em tempo real mesmo em imagens de baixa resolução, visto que estes não são propriamente identificados mas sim meramente posicionados sobre a imagem de entrada.
A principal limitação deste algoritmo é que o mesmo só se aplica a imagens com composição semelhante às utilizadas durante o treinamento da cascata, devido à necessidade de escolha dos pontos a serem utilizados na decisão durante essa etapa.