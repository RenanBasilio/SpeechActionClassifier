{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitspeechactionclassifierpipenv9f5f4c8910dd4870ae43479f8ed6aa94",
   "display_name": "Python 3.7.5 64-bit ('SpeechActionClassifier': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Tensorflow Version:  2.1.0\nNum GPUs Available:  1\n"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Flatten, Dropout, MaxPooling3D\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('export/data/dataset.npz')\n",
    "with np.load(path, mmap_mode=\"r\") as data:\n",
    "    train_examples = data['dataset'][:310]\n",
    "    train_labels = data['labels'][:310]\n",
    "    val_examples = data['dataset'][311:347]\n",
    "    val_labels = data['labels'][311:347]\n",
    "    test_examples = data['dataset'][347:386]\n",
    "    test_labels = data['labels'][347:386]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_examples, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d (Conv3D)              (None, 15, 237, 318, 16)  592       \n_________________________________________________________________\nmax_pooling3d (MaxPooling3D) (None, 7, 118, 159, 16)   0         \n_________________________________________________________________\nconv3d_1 (Conv3D)            (None, 7, 115, 157, 32)   6176      \n_________________________________________________________________\nmax_pooling3d_1 (MaxPooling3 (None, 3, 57, 78, 32)     0         \n_________________________________________________________________\nconv3d_2 (Conv3D)            (None, 3, 54, 76, 64)     24640     \n_________________________________________________________________\nmax_pooling3d_2 (MaxPooling3 (None, 1, 27, 38, 64)     0         \n_________________________________________________________________\nflatten (Flatten)            (None, 65664)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               33620480  \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 33,652,914\nTrainable params: 33,652,914\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv3D(16, (1, 4, 3), activation='relu', input_shape=(15, 240, 320, 3)),\n",
    "    MaxPooling3D(),\n",
    "    Conv3D(32, (1, 4, 3), activation='relu'),\n",
    "    MaxPooling3D(),\n",
    "    Conv3D(64, (1, 4, 3), activation='relu'),\n",
    "    MaxPooling3D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train for 78 steps, validate for 9 steps\nEpoch 1/100\n78/78 [==============================] - 28s 361ms/step - loss: 0.9677 - accuracy: 0.5387 - val_loss: 0.6889 - val_accuracy: 0.5556\nEpoch 2/100\n78/78 [==============================] - 19s 245ms/step - loss: 0.6914 - accuracy: 0.5871 - val_loss: 0.6818 - val_accuracy: 0.5556\nEpoch 3/100\n78/78 [==============================] - 18s 231ms/step - loss: 0.6407 - accuracy: 0.6129 - val_loss: 0.6211 - val_accuracy: 0.7778\nEpoch 4/100\n78/78 [==============================] - 18s 228ms/step - loss: 0.6279 - accuracy: 0.6871 - val_loss: 0.6463 - val_accuracy: 0.7222\nEpoch 5/100\n78/78 [==============================] - 18s 228ms/step - loss: 0.5718 - accuracy: 0.7194 - val_loss: 0.6315 - val_accuracy: 0.6667\nEpoch 6/100\n78/78 [==============================] - 18s 231ms/step - loss: 0.5212 - accuracy: 0.7516 - val_loss: 0.5760 - val_accuracy: 0.7222\nEpoch 7/100\n78/78 [==============================] - 18s 228ms/step - loss: 0.4342 - accuracy: 0.7968 - val_loss: 0.6508 - val_accuracy: 0.6667\nEpoch 8/100\n78/78 [==============================] - 18s 229ms/step - loss: 0.4397 - accuracy: 0.8000 - val_loss: 0.5997 - val_accuracy: 0.7778\nEpoch 9/100\n78/78 [==============================] - 18s 230ms/step - loss: 0.4245 - accuracy: 0.8000 - val_loss: 0.9925 - val_accuracy: 0.6944\n10/10 [==============================] - 1s 119ms/step - loss: 0.6523 - accuracy: 0.7179\n"
    },
    {
     "data": {
      "text/plain": "[0.6522874236106873, 0.71794873]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_dataset, epochs=100, callbacks=[callback], validation_data=val_dataset)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Exporting trained model to d:\\Dev\\Projects\\SpeechActionClassifier\\export\\model.h5\n"
    }
   ],
   "source": [
    "export_path = pathlib.Path(\"export/model.h5\")\n",
    "print(\"Exporting trained model to {}\".format(export_path.absolute()))\n",
    "\n",
    "model.save(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}